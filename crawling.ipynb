{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v67O-Un0eO8K"
      },
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/ares2012/temp/blob/master/Open_in_Colab.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IiMm0x1AcLPK"
      },
      "source": [
        "https://openincolab.com"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6sxvfkzdRXln"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6j4Dw7-9zGY"
      },
      "source": [
        "##### Google search\n",
        "\n",
        "https://jungwoon.github.io/python/2018/03/20/Data-Analysis-With-Python-3.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install googlesearch-python --upgrade --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import ssl\n",
        "\n",
        "context = ssl._create_unverified_context()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "BBdkZvw-HX3P",
        "outputId": "7af90f81-9119-4928-c964-e18699f55aa0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(\"Google Search몇 초 안에 이동하지 않는 경우 여기를 클릭하세요.If you're having trouble accessing Google Search, pleaseclick here, or sendfeedback.\",)"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import urllib.request\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "url = 'https://google.com/search?q=BHP'\n",
        "\n",
        "# Perform the request\n",
        "request = urllib.request.Request(url)\n",
        "\n",
        "# Set a normal User Agent header, otherwise Google will block the request.\n",
        "request.add_header('User-Agent', 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36')\n",
        "raw_response = urllib.request.urlopen(request, context=context).read()\n",
        "\n",
        "# Read the repsonse as a utf-8 string\n",
        "html = raw_response.decode(\"utf-8\")\n",
        "html\n",
        "\n",
        "soup = BeautifulSoup(html, \"html.parser\")\n",
        "soup.text, #soup.prettify(), soup.p['class'], soup.b.prettify()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from googlesearch import search\n",
        "\n",
        "proxy = 'http://API:@proxy.host.com:8080/'\n",
        "\n",
        "j = search(\"proxy test\", num_results=100, lang=\"en\", proxy=proxy, ssl_verify=False)\n",
        "for i in j:\n",
        "    print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "import urllib3\n",
        "\n",
        "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "h3-IiwK--RKj",
        "outputId": "8a393ea7-6971-40e0-da69-e7e1e7ddd1f7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "([SearchResult(url=https://www.bhp.com/, title=BHP: Our products help build a better, clearer future, description= What we produce. Copper for renewable energy. Iron ore and metallurgical coal for steel for new infrastructure. And potash to support more sustainable farming. ),\n",
              "  SearchResult(url=https://twitter.com/bhp?ref_src=twsrc%5Egoogle%7Ctwcamp%5Eserp%7Ctwgr%5Eauthor, title=, description=),\n",
              "  SearchResult(url=https://finance.yahoo.com/quote/BHP/, title=BHP Group Limited (BHP) Stock Price, News, Quote & History, description= BHP Group Limited operates as a resources company in Australia, Europe, China, Japan, India, South Korea, the rest of Asia, North America, South America, ... ),\n",
              "  SearchResult(url=http://www.bhp.com/, title=, description= BHP Group Limited, also known as Broken Hill Proprietary Company and formerly as BHP Billiton is an Australian multinational mining and metals public company that was founded in August 1885 and is headquartered in Melbourne.   Wikipedia ),\n",
              "  SearchResult(url=/search?num=12, title=  BHP (Iron ore company)  , description= BHP (Iron ore company) ),\n",
              "  SearchResult(url=https://www.google.com/search?num=12, title=, description=),\n",
              "  SearchResult(url=https://en.wikipedia.org/wiki/BHP, title=BHP - Wikipedia, description= BHP Billiton is an Australian multinational mining and metals public company that was founded in August 1885 and is headquartered in Melbourne. ),\n",
              "  SearchResult(url=https://au.linkedin.com/company/bhp, title=BHP - LinkedIn, description= We are supplying the resources the world needs to help build a better, clearer future. Copper for renewable energy. Potash for sustainable farming. ),\n",
              "  SearchResult(url=https://www.youtube.com/BHP, title=BHP - YouTube, description= Our purpose is to bring people and resources together to build a better world. ...more ...more bhp.comand 4 more links. Subscribe. ),\n",
              "  SearchResult(url=https://www.asx.com.au/markets/company/BHP, title=BHP share price and company information for ASX:BHP, description= View today's BHP share price, options, bonds, hybrids and warrants. View announcements, advanced pricing charts, trading status, fundamentals, ... )],\n",
              " 'https://www.bhp.com/',\n",
              " 'BHP: Our products help build a better, clearer future',\n",
              " ' What we produce. Copper for renewable energy. Iron ore and metallurgical coal for steel for new infrastructure. And potash to support more sustainable farming. ')"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from googlesearch import search\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "query = 'BHP'\n",
        "urls = []\n",
        "for url in search(query, num_results=10, advanced=True):\n",
        "  urls.append(url)\n",
        "\n",
        "urls, urls[0].url, urls[0].title, urls[0].description"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "READ TIMED OUT - SearchResult(url=https://www.bhp.com/, title=BHP: Our products help build a better, clearer future, description= What we produce. Copper for renewable energy. Iron ore and metallurgical coal for steel for new infrastructure. And potash to support more sustainable farming. )\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>url</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td></td>\n",
              "      <td>SearchResult(url=https://twitter.com/bhp?ref_s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td></td>\n",
              "      <td>SearchResult(url=https://finance.yahoo.com/quo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Google</td>\n",
              "      <td>SearchResult(url=https://www.google.com/search...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>BHP - Wikipedia</td>\n",
              "      <td>SearchResult(url=https://en.wikipedia.org/wiki...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td></td>\n",
              "      <td>SearchResult(url=https://au.linkedin.com/compa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>BHP - YouTube</td>\n",
              "      <td>SearchResult(url=https://www.youtube.com/BHP, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td></td>\n",
              "      <td>SearchResult(url=https://www.asx.com.au/market...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             title                                                url\n",
              "0                   SearchResult(url=https://twitter.com/bhp?ref_s...\n",
              "1                   SearchResult(url=https://finance.yahoo.com/quo...\n",
              "2           Google  SearchResult(url=https://www.google.com/search...\n",
              "3  BHP - Wikipedia  SearchResult(url=https://en.wikipedia.org/wiki...\n",
              "4                   SearchResult(url=https://au.linkedin.com/compa...\n",
              "5    BHP - YouTube  SearchResult(url=https://www.youtube.com/BHP, ...\n",
              "6                   SearchResult(url=https://www.asx.com.au/market..."
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''불필요'''\n",
        "\n",
        "crawl_rst = dict()\n",
        "crawl_list = list()\n",
        "for url in urls[:]:\n",
        "  #print(url.url)\n",
        "  if (url.url).startswith('https://'):\n",
        "    try:\n",
        "      with requests.get(url.url, verify=False, timeout=3, stream=True) as url_result:\n",
        "        html = url_result.text\n",
        "        soup = BeautifulSoup(html, \"html.parser\")\n",
        "        text = soup.get_text()\n",
        "        #print(soup.title)\n",
        "        tt = ''\n",
        "        if soup.title is not None:\n",
        "          tt = soup.title.string\n",
        "          #print(soup.title.find_all(string=True))\n",
        "        #soup.b.prettify()\n",
        "        crawl_rst['title']=tt\n",
        "        crawl_rst['url']=url\n",
        "        crawl_list.append(crawl_rst.copy())\n",
        "        #print(crawl_list)\n",
        "    except requests.exceptions.ReadTimeout:\n",
        "      print (\"READ TIMED OUT -\", url)\n",
        "\n",
        "df=pd.DataFrame(crawl_list)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFjZbLBNGyiW"
      },
      "source": [
        "##### Google News"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uaa_bQlzBZ3S",
        "outputId": "215de99f-3ba1-4ebb-af7f-34f58bcbb9d7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip available: 22.3.1 -> 25.0.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install GoogleNews --upgrade --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwDR0XhDBgLt",
        "outputId": "afb7af97-a28e-4523-859f-b604f3663594"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  DEPRECATION: tinysegmenter is being installed using the legacy 'setup.py install' method, because it does not have a 'pyproject.toml' and the 'wheel' package is not installed. pip 23.1 will enforce this behaviour change. A possible replacement is to enable the '--use-pep517' option. Discussion can be found at https://github.com/pypa/pip/issues/8559\n",
            "  DEPRECATION: sgmllib3k is being installed using the legacy 'setup.py install' method, because it does not have a 'pyproject.toml' and the 'wheel' package is not installed. pip 23.1 will enforce this behaviour change. A possible replacement is to enable the '--use-pep517' option. Discussion can be found at https://github.com/pypa/pip/issues/8559\n",
            "  DEPRECATION: jieba3k is being installed using the legacy 'setup.py install' method, because it does not have a 'pyproject.toml' and the 'wheel' package is not installed. pip 23.1 will enforce this behaviour change. A possible replacement is to enable the '--use-pep517' option. Discussion can be found at https://github.com/pypa/pip/issues/8559\n",
            "  DEPRECATION: feedfinder2 is being installed using the legacy 'setup.py install' method, because it does not have a 'pyproject.toml' and the 'wheel' package is not installed. pip 23.1 will enforce this behaviour change. A possible replacement is to enable the '--use-pep517' option. Discussion can be found at https://github.com/pypa/pip/issues/8559\n",
            "\n",
            "[notice] A new release of pip available: 22.3.1 -> 25.0.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install newspaper3k --upgrade --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "eH0gDW1jB2Tl"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip available: 22.3.1 -> 25.0.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install lxml lxml_html_clean  --upgrade --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "id": "lwJl0gHlBXrs",
        "outputId": "f082a647-8196-4807-d628-1ec6e3a2b6de"
      },
      "outputs": [],
      "source": [
        "from GoogleNews import GoogleNews\n",
        "from newspaper import Article\n",
        "import pandas as pd\n",
        "\n",
        "search_term = \"BHP\"\n",
        "\n",
        "# I suppose the date is in \"MM/dd/yyyy\" format...\n",
        "googlenews=GoogleNews(start='03/01/2025',end='03/03/2025') \n",
        "googlenews=GoogleNews(lang='en', region='KR')\n",
        "googlenews.search(search_term)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>media</th>\n",
              "      <th>date</th>\n",
              "      <th>datetime</th>\n",
              "      <th>desc</th>\n",
              "      <th>link</th>\n",
              "      <th>img</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2025 MG Comet EV launched at Rs 4.99 lakh</td>\n",
              "      <td>Team-BHP</td>\n",
              "      <td>2 hours ago</td>\n",
              "      <td>2025-03-20 07:41:20.141401</td>\n",
              "      <td>The Comet EV now gets new features such as a r...</td>\n",
              "      <td>https://www.team-bhp.com/news/2025-mg-comet-ev...</td>\n",
              "      <td>data:image/gif;base64,R0lGODlhAQABAIAAAP//////...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Tobias Wagner and his electric trucking adventure</td>\n",
              "      <td>Team-BHP</td>\n",
              "      <td>3 hours ago</td>\n",
              "      <td>2025-03-20 06:41:20.143400</td>\n",
              "      <td>I have been following the youtube channel of T...</td>\n",
              "      <td>https://www.team-bhp.com/forum/electric-cars/2...</td>\n",
              "      <td>data:image/gif;base64,R0lGODlhAQABAIAAAP//////...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ducati Scrambler Icon Dark launched at Rs 9.97...</td>\n",
              "      <td>Team-BHP</td>\n",
              "      <td>4 hours ago</td>\n",
              "      <td>2025-03-20 05:41:20.144400</td>\n",
              "      <td>Ducati has launched the Scrambler Icon Dark in...</td>\n",
              "      <td>https://www.team-bhp.com/news/ducati-scrambler...</td>\n",
              "      <td>data:image/gif;base64,R0lGODlhAQABAIAAAP//////...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Maruti Suzuki Tour S based on new-gen Dzire la...</td>\n",
              "      <td>Team-BHP</td>\n",
              "      <td>4 hours ago</td>\n",
              "      <td>2025-03-20 05:41:20.145401</td>\n",
              "      <td>The Tour S is priced at Rs 6.79 lakh for the p...</td>\n",
              "      <td>https://www.team-bhp.com/news/maruti-suzuki-to...</td>\n",
              "      <td>data:image/gif;base64,R0lGODlhAQABAIAAAP//////...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Ultraviolette Tesseract surpasses 50,000 bookings</td>\n",
              "      <td>Team-BHP</td>\n",
              "      <td>7 hours ago</td>\n",
              "      <td>2025-03-20 02:41:20.146400</td>\n",
              "      <td>The Tesseract comes with three battery options...</td>\n",
              "      <td>https://www.team-bhp.com/news/ultraviolette-te...</td>\n",
              "      <td>data:image/gif;base64,R0lGODlhAQABAIAAAP//////...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175</th>\n",
              "      <td>TVS Apache RTX 300 ADV design patent filed in ...</td>\n",
              "      <td>Team-BHP</td>\n",
              "      <td>2 days ago</td>\n",
              "      <td>2025-03-18 09:44:52.985809</td>\n",
              "      <td>The patent image reveals a road-biased ADV tha...</td>\n",
              "      <td>https://www.team-bhp.com/news/tvs-apache-rtx-3...</td>\n",
              "      <td>data:image/gif;base64,R0lGODlhAQABAIAAAP//////...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176</th>\n",
              "      <td>8 mid-size bikes in India</td>\n",
              "      <td>India Today</td>\n",
              "      <td>2 days ago</td>\n",
              "      <td>2025-03-18 09:44:52.992763</td>\n",
              "      <td>The Royal Enfield Hunter 350 is powered by a 3...</td>\n",
              "      <td>https://www.indiatoday.in/visualstories/auto/8...</td>\n",
              "      <td>data:image/gif;base64,R0lGODlhAQABAIAAAP//////...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177</th>\n",
              "      <td>Limited edition Jeep Compass Sandstorm launche...</td>\n",
              "      <td>Team-BHP</td>\n",
              "      <td>2 days ago</td>\n",
              "      <td>2025-03-18 09:44:52.999803</td>\n",
              "      <td>Jeep has launched the Compass Sandstorm Editio...</td>\n",
              "      <td>https://www.team-bhp.com/news/limited-edition-...</td>\n",
              "      <td>data:image/gif;base64,R0lGODlhAQABAIAAAP//////...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>178</th>\n",
              "      <td>Skoda Auto VW India achieves 5 lakh engine pro...</td>\n",
              "      <td>Team-BHP</td>\n",
              "      <td>2 days ago</td>\n",
              "      <td>2025-03-18 09:44:53.005811</td>\n",
              "      <td>Skoda Auto VW India has achieved a new product...</td>\n",
              "      <td>https://www.team-bhp.com/news/skoda-auto-vw-in...</td>\n",
              "      <td>data:image/gif;base64,R0lGODlhAQABAIAAAP//////...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>179</th>\n",
              "      <td>Atria Investments Inc Has $376,000 Stake in BH...</td>\n",
              "      <td>Defense World</td>\n",
              "      <td>2 days ago</td>\n",
              "      <td>2025-03-18 09:44:53.012763</td>\n",
              "      <td>Read Atria Investments Inc Has $376000 Stake i...</td>\n",
              "      <td>https://www.defenseworld.net/2025/03/17/atria-...</td>\n",
              "      <td>data:image/gif;base64,R0lGODlhAQABAIAAAP//////...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>180 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 title          media  \\\n",
              "0            2025 MG Comet EV launched at Rs 4.99 lakh       Team-BHP   \n",
              "1    Tobias Wagner and his electric trucking adventure       Team-BHP   \n",
              "2    Ducati Scrambler Icon Dark launched at Rs 9.97...       Team-BHP   \n",
              "3    Maruti Suzuki Tour S based on new-gen Dzire la...       Team-BHP   \n",
              "4    Ultraviolette Tesseract surpasses 50,000 bookings       Team-BHP   \n",
              "..                                                 ...            ...   \n",
              "175  TVS Apache RTX 300 ADV design patent filed in ...       Team-BHP   \n",
              "176                          8 mid-size bikes in India    India Today   \n",
              "177  Limited edition Jeep Compass Sandstorm launche...       Team-BHP   \n",
              "178  Skoda Auto VW India achieves 5 lakh engine pro...       Team-BHP   \n",
              "179  Atria Investments Inc Has $376,000 Stake in BH...  Defense World   \n",
              "\n",
              "            date                   datetime  \\\n",
              "0    2 hours ago 2025-03-20 07:41:20.141401   \n",
              "1    3 hours ago 2025-03-20 06:41:20.143400   \n",
              "2    4 hours ago 2025-03-20 05:41:20.144400   \n",
              "3    4 hours ago 2025-03-20 05:41:20.145401   \n",
              "4    7 hours ago 2025-03-20 02:41:20.146400   \n",
              "..           ...                        ...   \n",
              "175   2 days ago 2025-03-18 09:44:52.985809   \n",
              "176   2 days ago 2025-03-18 09:44:52.992763   \n",
              "177   2 days ago 2025-03-18 09:44:52.999803   \n",
              "178   2 days ago 2025-03-18 09:44:53.005811   \n",
              "179   2 days ago 2025-03-18 09:44:53.012763   \n",
              "\n",
              "                                                  desc  \\\n",
              "0    The Comet EV now gets new features such as a r...   \n",
              "1    I have been following the youtube channel of T...   \n",
              "2    Ducati has launched the Scrambler Icon Dark in...   \n",
              "3    The Tour S is priced at Rs 6.79 lakh for the p...   \n",
              "4    The Tesseract comes with three battery options...   \n",
              "..                                                 ...   \n",
              "175  The patent image reveals a road-biased ADV tha...   \n",
              "176  The Royal Enfield Hunter 350 is powered by a 3...   \n",
              "177  Jeep has launched the Compass Sandstorm Editio...   \n",
              "178  Skoda Auto VW India has achieved a new product...   \n",
              "179  Read Atria Investments Inc Has $376000 Stake i...   \n",
              "\n",
              "                                                  link  \\\n",
              "0    https://www.team-bhp.com/news/2025-mg-comet-ev...   \n",
              "1    https://www.team-bhp.com/forum/electric-cars/2...   \n",
              "2    https://www.team-bhp.com/news/ducati-scrambler...   \n",
              "3    https://www.team-bhp.com/news/maruti-suzuki-to...   \n",
              "4    https://www.team-bhp.com/news/ultraviolette-te...   \n",
              "..                                                 ...   \n",
              "175  https://www.team-bhp.com/news/tvs-apache-rtx-3...   \n",
              "176  https://www.indiatoday.in/visualstories/auto/8...   \n",
              "177  https://www.team-bhp.com/news/limited-edition-...   \n",
              "178  https://www.team-bhp.com/news/skoda-auto-vw-in...   \n",
              "179  https://www.defenseworld.net/2025/03/17/atria-...   \n",
              "\n",
              "                                                   img  \n",
              "0    data:image/gif;base64,R0lGODlhAQABAIAAAP//////...  \n",
              "1    data:image/gif;base64,R0lGODlhAQABAIAAAP//////...  \n",
              "2    data:image/gif;base64,R0lGODlhAQABAIAAAP//////...  \n",
              "3    data:image/gif;base64,R0lGODlhAQABAIAAAP//////...  \n",
              "4    data:image/gif;base64,R0lGODlhAQABAIAAAP//////...  \n",
              "..                                                 ...  \n",
              "175  data:image/gif;base64,R0lGODlhAQABAIAAAP//////...  \n",
              "176  data:image/gif;base64,R0lGODlhAQABAIAAAP//////...  \n",
              "177  data:image/gif;base64,R0lGODlhAQABAIAAAP//////...  \n",
              "178  data:image/gif;base64,R0lGODlhAQABAIAAAP//////...  \n",
              "179  data:image/gif;base64,R0lGODlhAQABAIAAAP//////...  \n",
              "\n",
              "[180 rows x 7 columns]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Initial list of results - it will contain a list of dictionaries (dict).\n",
        "results = []\n",
        "\n",
        "# Contains the final results = news filtered by the criteria\n",
        "# (news that in their description contains the search term).\n",
        "final_results = []\n",
        "\n",
        "# Get first 4 pages with the results and append those results to the list - you can set any other range according to  your needs:\n",
        "for page in range(1,4):\n",
        "  googlenews.getpage(page) # Consider add an timer for avoid multiple calls and get \"HTTP Error 429: Too Many Requests\" error.\n",
        "  results.extend(googlenews.result())\n",
        "\n",
        "# Remove duplicates and include to the \"final_results\" list\n",
        "# only the news that includes in their description the search term:\n",
        "for item in results:\n",
        "  if (item not in final_results and (search_term in item[\"desc\"])):\n",
        "    final_results.append(item)\n",
        "\n",
        "# Build and show the final dataframe:\n",
        "df=pd.DataFrame(results)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### melon with BeautifulSoup "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1. G-DRAGON - TOO BAD (feat. Anderson .Paak)\n",
            "2. 조째즈 - 모르시나요(PROD.로코베리)\n",
            "3. 제니 (JENNIE) - like JENNIE\n",
            "4. G-DRAGON - HOME SWEET HOME (feat. 태양, 대성)\n",
            "5. IVE (아이브) - REBEL HEART\n",
            "6. WOODZ - Drowning\n",
            "7. 황가람 - 나는 반딧불\n",
            "8. aespa - Whiplash\n",
            "9. BOYNEXTDOOR - 오늘만 I LOVE YOU\n",
            "10. IVE (아이브) - ATTITUDE\n",
            "11. 로제 (ROSÉ) - APT.\n",
            "12. G-DRAGON - TAKE ME\n",
            "13. 로제 (ROSÉ) - toxic till the end\n",
            "14. DAY6 (데이식스) - HAPPY\n",
            "15. G-DRAGON - PO￦ER\n",
            "16. 로이킴 - 내게 사랑이 뭐냐고 물어본다면\n",
            "17. 황가람 - 미치게 그리워서\n",
            "18. PLAVE - Dash\n",
            "19. 이클립스 (ECLIPSE) - 소나기\n",
            "20. BABYMONSTER - DRIP\n",
            "21. KiiiKiii (키키) - I DO ME\n",
            "22. 이창섭 - 천상연\n",
            "23. DAY6 (데이식스) - Welcome to the Show\n",
            "24. aespa - Supernova\n",
            "25. DAY6 (데이식스) - 한 페이지가 될 수 있게\n",
            "26. Hearts2Hearts (하츠투하츠) - The Chase\n",
            "27. PLAVE - RIZZ\n",
            "28. 이무진 - 청춘만화\n",
            "29. 임영웅 - 사랑은 늘 도망가\n",
            "30. LE SSERAFIM (르세라핌) - HOT\n",
            "31. 순순희(지환) - 슬픈 초대장\n",
            "32. aespa - UP (KARINA Solo)\n",
            "33. PLAVE - Island\n",
            "34. AKMU (악뮤) - 어떻게 이별까지 사랑하겠어, 널 사랑하는 거지\n",
            "35. QWER - 내 이름 맑음\n",
            "36. PLAVE - Chroma Drift\n",
            "37. DAY6 (데이식스) - 예뻤어\n",
            "38. Lady Gaga - Die With A Smile\n",
            "39. PLAVE - 12:32 (A to T)\n",
            "40. 아이유 - Love wins all\n",
            "41. 임영웅 - 우리들의 블루스\n",
            "42. 재쓰비 (JAESSBEE) - 너와의 모든 지금\n",
            "43. QWER - 고민중독\n",
            "44. G-DRAGON - DRAMA\n",
            "45. NewJeans - How Sweet\n",
            "46. G-DRAGON - 무제(無題) (Untitled, 2014)\n",
            "47. 임영웅 - 온기\n",
            "48. 너드커넥션 (Nerd Connection) - 그대만 있다면 (여름날 우리 X 너드커넥션 (Nerd Connection))\n",
            "49. 성시경 - 너의 모든 순간\n",
            "50. 오반(OVAN) - Flower\n"
          ]
        }
      ],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "\n",
        "headers = {'User-Agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.86 Safari/537.36'}\n",
        "data = requests.get('https://www.melon.com/chart/', headers=headers, verify=False)\n",
        "\n",
        "soup = BeautifulSoup(data.text, 'html.parser')\n",
        "\n",
        "# print(soup)\n",
        "\n",
        "top_100 = soup.select('#lst50 > td > div') #tr로 이루어진 list\n",
        " \n",
        "for tr in top_100 :\n",
        "    rank = tr.select_one('span.rank')\n",
        "        \n",
        "    if rank is not None:\n",
        "        print(rank.text, end=\". \")\n",
        "        \n",
        "    title = tr.select_one('div > div.ellipsis.rank01 > span > a')\n",
        "    \n",
        "    if title is not None:\n",
        "        artist = tr.select_one('div.ellipsis.rank02 > a').text\n",
        "        print(artist,'-', title.text)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzfVX5zaHGd2"
      },
      "source": [
        "##### GDELT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4nuRJlCgJhIy",
        "outputId": "f5cfeb42-c1b0-4068-aaa7-18a0064f70a0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(4479,\n",
              " ['20250317.export.CSV.zip',\n",
              "  '20250316.export.CSV.zip',\n",
              "  '20250315.export.CSV.zip',\n",
              "  '20250314.export.CSV.zip',\n",
              "  '20250313.export.CSV.zip'])"
            ]
          },
          "execution_count": 121,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import requests\n",
        "import lxml.html as lh\n",
        "\n",
        "gdelt_base_url = 'http://data.gdeltproject.org/events/'\n",
        "\n",
        "# get the list of all the links on the gdelt file page\n",
        "page = requests.get(gdelt_base_url+'index.html')\n",
        "doc = lh.fromstring(page.content)\n",
        "link_list = doc.xpath(\"//*/ul/li/a/@href\")\n",
        "\n",
        "# separate out those links that begin with four digits\n",
        "file_list = [x for x in link_list if str.isdigit(x[0:4])]\n",
        "len(file_list), file_list[0:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "id": "cCNImevPJlVi",
        "outputId": "5c5acd88-e6f6-4594-ba53-0ff50264ffeb"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20250317.</span>export.CSV.zip\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1;36m20250317.\u001b[0mexport.CSV.zip\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">extracting,\n",
              "</pre>\n"
            ],
            "text/plain": [
              "extracting,\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">parsing,\n",
              "</pre>\n"
            ],
            "text/plain": [
              "parsing,\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "IndexError",
          "evalue": "list index out of range",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-137-5173b8b9490a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                 \u001b[0;31m# extract lines with our interest country code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mfips_country_code\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitemgetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m51\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m37\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m44\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m                     \u001b[0moutfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0moutfilecounter\u001b[0m \u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ],
      "source": [
        "import os.path\n",
        "import urllib\n",
        "import zipfile\n",
        "import glob\n",
        "import operator\n",
        "\n",
        "infilecounter = 0\n",
        "outfilecounter = 0\n",
        "\n",
        "local_path = './GDELT_Data/'\n",
        "#fips_country_code = 'UK'\n",
        "fips_country_code = 'AU'\n",
        "\n",
        "\n",
        "for compressed_file in file_list[infilecounter:]:\n",
        "    print(compressed_file)\n",
        "\n",
        "    # if we dont have the compressed file stored locally, go get it. Keep trying if necessary.\n",
        "    while not os.path.isfile(local_path+compressed_file):\n",
        "        print( 'downloading,',)\n",
        "        urllib.request.urlretrieve(url=gdelt_base_url+compressed_file,\n",
        "                           filename=local_path+compressed_file)\n",
        "\n",
        "    # extract the contents of the compressed file to a temporary directory\n",
        "    print( 'extracting,',)\n",
        "    z = zipfile.ZipFile(file=local_path+compressed_file, mode='r')\n",
        "    z.extractall(path=local_path+'tmp/')\n",
        "\n",
        "    # parse each of the csv files in the working directory,\n",
        "    print( 'parsing,',)\n",
        "    for infile_name in glob.glob(local_path+'tmp/*'):\n",
        "        outfile_name = local_path+'country/'+fips_country_code+'%04i.tsv'%outfilecounter\n",
        "\n",
        "        # open the infile and outfile\n",
        "        with open(infile_name, mode='r') as infile, open(outfile_name, mode='w') as outfile:\n",
        "            for line in infile:\n",
        "                # extract lines with our interest country code\n",
        "                if fips_country_code in operator.itemgetter(51, 37, 44)(line.split('\\t')):\n",
        "                    outfile.write(line)\n",
        "            outfilecounter +=1\n",
        "\n",
        "        # delete the temporary file\n",
        "        os.remove(infile_name)\n",
        "    infilecounter +=1\n",
        "    print( 'done')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "GrjDwsm7KhW2",
        "outputId": "94e7f4c8-8198-458a-a58a-db743fa1b077"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'CSV.header.fieldids.xlsx'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-132-71fd55693368>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Get the GDELT field names from a helper file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m colnames = pd.read_excel('CSV.header.fieldids.xlsx', sheet_name='Sheet1', \n\u001b[0m\u001b[1;32m      6\u001b[0m                          index_col='Column ID', usecols=[0,1])['Field Name']\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[1;32m    493\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m         io = ExcelFile(\n\u001b[0m\u001b[1;32m    496\u001b[0m             \u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[1;32m   1548\u001b[0m                 \u001b[0mext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xls\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1549\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1550\u001b[0;31m                 ext = inspect_excel_format(\n\u001b[0m\u001b[1;32m   1551\u001b[0m                     \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1400\u001b[0m         \u001b[0mcontent_or_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_or_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1402\u001b[0;31m     with get_handle(\n\u001b[0m\u001b[1;32m   1403\u001b[0m         \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1404\u001b[0m     ) as handle:\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'CSV.header.fieldids.xlsx'"
          ]
        }
      ],
      "source": [
        "import glob\n",
        "import pandas as pd\n",
        "\n",
        "# Get the GDELT field names from a helper file\n",
        "colnames = pd.read_excel('CSV.header.fieldids.xlsx', sheet_name='Sheet1',\n",
        "                         index_col='Column ID', usecols=[0,1])['Field Name']\n",
        "\n",
        "# Build DataFrames from each of the intermediary files\n",
        "files = glob.glob(local_path+'country/'+fips_country_code+'*')\n",
        "DFlist = []\n",
        "for active_file in files:\n",
        "    print( active_file)\n",
        "    DFlist.append(pd.read_csv(active_file, sep='\\t', header=None, dtype=str,\n",
        "                              names=colnames, index_col=['GLOBALEVENTID']))\n",
        "\n",
        "# Merge the file-based dataframes and save a pickle\n",
        "DF = pd.concat(DFlist)\n",
        "DF.to_pickle(local_path+'backup'+fips_country_code+'.pickle')\n",
        "\n",
        "# once everythin is safely stored away, remove the temporary files\n",
        "for active_file in files:\n",
        "    os.remove(active_file)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

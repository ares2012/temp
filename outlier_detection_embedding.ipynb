{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas matplotlib scikit-learn matplotlib-venn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib_venn import venn3\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_outlier_methods_with_venn_tfidf(\n",
    "    df, \n",
    "    text_column, \n",
    "    contamination=0.2, \n",
    "    pca_dim=50, \n",
    "    perplexity=5,\n",
    "    dbscan_eps=1.5,\n",
    "    dbscan_min_samples=2\n",
    "):\n",
    "    texts = df[text_column].astype(str).tolist()\n",
    "\n",
    "    # 1. TF-IDF 벡터화\n",
    "    print(\"🔄 TF-IDF 벡터화 중...\")\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X = vectorizer.fit_transform(texts).toarray()\n",
    "\n",
    "    # 2. PCA로 차원 축소\n",
    "    print(f\"📉 PCA로 {pca_dim}차원 축소 중...\")\n",
    "    pca = PCA(n_components=min(pca_dim, X.shape[1]), random_state=42)\n",
    "    X_pca = pca.fit_transform(X)\n",
    "\n",
    "    # 3. t-SNE로 2차원 축소\n",
    "    print(\"🎨 t-SNE 시각화 좌표 계산 중...\")\n",
    "    tsne = TSNE(n_components=2, perplexity=perplexity, random_state=42, init='pca', learning_rate='auto')\n",
    "    X_tsne = tsne.fit_transform(X_pca)\n",
    "\n",
    "    # 4. Isolation Forest\n",
    "    iso = IsolationForest(contamination=contamination, random_state=42)\n",
    "    labels_iso = iso.fit_predict(X)\n",
    "\n",
    "    # 5. LOF\n",
    "    lof = LocalOutlierFactor(n_neighbors=5, contamination=contamination)\n",
    "    labels_lof = lof.fit_predict(X)\n",
    "\n",
    "    # 6. DBSCAN\n",
    "    dbscan = DBSCAN(eps=dbscan_eps, min_samples=dbscan_min_samples)\n",
    "    db_labels = dbscan.fit_predict(X)\n",
    "    labels_dbscan = np.where(db_labels == -1, -1, 1)\n",
    "\n",
    "    # 7. 이상치 인덱스 집합\n",
    "    set_iso = {i for i, l in enumerate(labels_iso) if l == -1}\n",
    "    set_lof = {i for i, l in enumerate(labels_lof) if l == -1}\n",
    "    set_db = {i for i, l in enumerate(labels_dbscan) if l == -1}\n",
    "\n",
    "    # 8. Venn Diagram\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    venn3(\n",
    "        subsets=(set_iso, set_lof, set_db),\n",
    "        set_labels=('Isolation Forest', 'LOF', 'DBSCAN')\n",
    "    )\n",
    "    plt.title(\"이상치 탐지 알고리즘 비교 (Venn Diagram)\")\n",
    "    plt.show()\n",
    "\n",
    "    # 9. t-SNE 시각화\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(20, 6))\n",
    "    colors_iso = ['red' if l == -1 else 'blue' for l in labels_iso]\n",
    "    colors_lof = ['red' if l == -1 else 'blue' for l in labels_lof]\n",
    "    colors_db = ['red' if l == -1 else 'blue' for l in labels_dbscan]\n",
    "\n",
    "    axes[0].scatter(X_tsne[:, 0], X_tsne[:, 1], c=colors_iso, s=100, alpha=0.7)\n",
    "    axes[0].set_title(\"Isolation Forest\")\n",
    "    axes[1].scatter(X_tsne[:, 0], X_tsne[:, 1], c=colors_lof, s=100, alpha=0.7)\n",
    "    axes[1].set_title(\"LOF\")\n",
    "    axes[2].scatter(X_tsne[:, 0], X_tsne[:, 1], c=colors_db, s=100, alpha=0.7)\n",
    "    axes[2].set_title(f\"DBSCAN (eps={dbscan_eps}, min_samples={dbscan_min_samples})\")\n",
    "\n",
    "    for ax in axes:\n",
    "        ax.grid(True)\n",
    "\n",
    "    plt.suptitle(\"TF-IDF 기반 이상치 탐지 비교 (t-SNE 시각화)\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # 10. 결과 반환\n",
    "    results = {\n",
    "        \"IsolationForest\": [{\"text\": texts[i], \"label\": \"이상치\" if i in set_iso else \"정상\"} for i in range(len(texts))],\n",
    "        \"LOF\": [{\"text\": texts[i], \"label\": \"이상치\" if i in set_lof else \"정상\"} for i in range(len(texts))],\n",
    "        \"DBSCAN\": [{\"text\": texts[i], \"label\": \"이상치\" if i in set_db else \"정상\"} for i in range(len(texts))]\n",
    "    }\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 샘플 데이터프레임\n",
    "data = {\n",
    "    \"id\": [1, 2, 3, 4, 5, 6, 7, 8],\n",
    "    \"text\": [\n",
    "        \"오늘 날씨가 좋다.\",\n",
    "        \"주식 시장이 상승했다.\",\n",
    "        \"점심으로 파스타를 먹었다.\",\n",
    "        \"비트코인 가격이 급락했다.\",\n",
    "        \"asdfghjkl qwertyuiop\",\n",
    "        \"내일은 비가 올 것 같다.\",\n",
    "        \"환율이 급등했다.\",\n",
    "        \"저녁에 치킨을 먹었다.\"\n",
    "    ]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = compare_outlier_methods_with_venn_tfidf(\n",
    "    df, \n",
    "    text_column=\"text\", \n",
    "    contamination=0.2, \n",
    "    pca_dim=50, \n",
    "    perplexity=5,\n",
    "    dbscan_eps=1.5,\n",
    "    dbscan_min_samples=2\n",
    ")\n",
    "\n",
    "print(\"\\n=== Isolation Forest 결과 ===\")\n",
    "for r in results[\"IsolationForest\"]:\n",
    "    print(f\"{r['text']} -> {r['label']}\")\n",
    "\n",
    "print(\"\\n=== LOF 결과 ===\")\n",
    "for r in results[\"LOF\"]:\n",
    "    print(f\"{r['text']} -> {r['label']}\")\n",
    "\n",
    "print(\"\\n=== DBSCAN 결과 ===\")\n",
    "for r in results[\"DBSCAN\"]:\n",
    "    print(f\"{r['text']} -> {r['label']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
